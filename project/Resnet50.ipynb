{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.preprocessing import image as image_prepocessor\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from keras.models import Sequential  \n",
    "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D \n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/home/paperspace/data/dogBreed/\"\n",
    "# data_path = r\"E:\\DogBreed\"\n",
    "im_size = 225\n",
    "batch_size = 64\n",
    "epochs = 50\n",
    "_seed = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.resnet50 import preprocess_input\n",
    "model = ResNet50(include_top=False, weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "_training_image_loc = os.path.join(data_path, \"train\")\n",
    "_training_label_loc = os.path.join(data_path, \"labels.csv\")\n",
    "_testing_image_loc = os.path.join(data_path, \"test\")\n",
    "_sample_sub_loc = os.path.join(data_path, \"sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_dir = \"temp\"\n",
    "if not os.path.exists(temp_dir):\n",
    "    os.mkdir(temp_dir)\n",
    "    \n",
    "bottle_ft_train_path = os.path.join(temp_dir,'btn_ft_train_{}_{}.npy'.format(im_size, batch_size))\n",
    "bottle_ft_val_path = os.path.join(temp_dir,'btn_ft_val_{}_{}.npy'.format(im_size, batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_images_into_breed(dataframe, new_dir_name):\n",
    "    sub_path = os.path.join(_training_image_loc, new_dir_name)\n",
    "    \n",
    "    if os.path.exists(sub_path):\n",
    "        print(\"Folder {} exists.\".format(sub_path))\n",
    "        return sub_path\n",
    "    \n",
    "    os.mkdir(sub_path)\n",
    "        \n",
    "    for name, group in tqdm(dataframe.groupby(\"breed\")):\n",
    "        breed_dir = os.path.join(sub_path, name)\n",
    "        if not os.path.exists(breed_dir):\n",
    "            os.mkdir(breed_dir)\n",
    "        for file_name in group[\"id\"]:\n",
    "            file_path = os.path.join(_training_image_loc, file_name + \".jpg\")\n",
    "            if os.path.exists(file_path):\n",
    "                shutil.copy(file_path, breed_dir)\n",
    "    return sub_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder /home/paperspace/data/dogBreed/train/train exists.\n",
      "Folder /home/paperspace/data/dogBreed/train/valid exists.\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(_training_label_loc)\n",
    "\n",
    "np.random.seed(seed=_seed)\n",
    "rnd = np.random.random(df.shape[0])\n",
    "train_idx = rnd < 0.8\n",
    "valid_idx = rnd >= 0.8\n",
    "\n",
    "traing_df = df[train_idx]\n",
    "validation_df = df[valid_idx]\n",
    "train_data_loc = split_images_into_breed(traing_df, \"train\")\n",
    "val_data_loc = split_images_into_breed(validation_df, \"valid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8221 images belonging to 120 classes.\n"
     ]
    }
   ],
   "source": [
    "data_generator = ImageDataGenerator(rescale=None)\n",
    "if not os.path.exists(bottle_ft_train_path):\n",
    "    train_generator = data_generator.flow_from_directory(train_data_loc,\n",
    "                                                         target_size=(im_size, im_size), \n",
    "                                                         batch_size=batch_size,\n",
    "                                                         class_mode=None,\n",
    "                                                         shuffle=False)\n",
    "    num_of_training_samples = len(train_generator.filenames)\n",
    "    num_classes = len(train_generator.class_indices)\n",
    "    steps = int(math.ceil(num_of_training_samples / batch_size))  \n",
    "\n",
    "    bottleneck_features_train = model.predict_generator(train_generator, steps)\n",
    "    np.save(bottle_ft_train_path, bottleneck_features_train)\n",
    "else:\n",
    "    print(\"Skipping saving of train data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2001 images belonging to 120 classes.\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(bottle_ft_val_path):\n",
    "    val_generator = data_generator.flow_from_directory(val_data_loc,\n",
    "                                                       target_size=(im_size, im_size), \n",
    "                                                       batch_size=batch_size,\n",
    "                                                       class_mode=None,\n",
    "                                                       shuffle=False)\n",
    "    num_of_val_samples = len(val_generator.filenames)\n",
    "    steps = int(math.ceil(num_of_val_samples / batch_size))  \n",
    "\n",
    "    bottleneck_features_val = model.predict_generator(val_generator)\n",
    "    np.save(bottle_ft_val_path, bottleneck_features_val)  \n",
    "else:\n",
    "    print(\"Skipping saving of validation data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator with images and Labels\n",
    "train_generator = data_generator.flow_from_directory(train_data_loc,\n",
    "                                                     target_size=(im_size, im_size), \n",
    "                                                     batch_size=batch_size,\n",
    "                                                     class_mode='categorical',\n",
    "                                                     shuffle=False)\n",
    "num_of_training_samples = len(train_generator.filenames)\n",
    "num_classes = len(train_generator.class_indices)\n",
    "\n",
    "train_data = np.load(bottle_ft_train_path)\n",
    "train_labels = train_generator.classes.reshape(-1, 1)\n",
    "encoder = OneHotEncoder()\n",
    "train_labels = encoder.fit_transform(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_generator = data_generator.flow_from_directory(val_data_loc,\n",
    "                                                   target_size=(im_size, im_size), \n",
    "                                                   batch_size=batch_size,\n",
    "                                                   class_mode=None,\n",
    "                                                   shuffle=False)\n",
    "num_of_val_samples = len(val_generator.filenames)\n",
    "validation_data = np.load(bottle_ft_val_path)  \n",
    "validation_labels = val_generator.classes.reshape(-1, 1)\n",
    "encoder = OneHotEncoder()\n",
    "validation_labels = encoder.fit_transform(validation_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=train_data.shape[1:]))\n",
    "model.add(Dense(2048, activation=\"relu\"))\n",
    "model.add(Dropout(0.8))\n",
    "# model.add(Dense(256, activation=\"relu\"))\n",
    "# model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "history = model.fit(train_data, train_labels, epochs=epochs, batch_size=batch_size,\n",
    "                   validation_data=(validation_data, validation_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1)  \n",
    "   \n",
    "# summarize history for accuracy  \n",
    "   \n",
    "plt.subplot(211)  \n",
    "plt.plot(history.history['acc'])  \n",
    "plt.plot(history.history['val_acc'])  \n",
    "plt.title('model accuracy')  \n",
    "plt.ylabel('accuracy')  \n",
    "plt.xlabel('epoch')  \n",
    "plt.legend(['train', 'test'], loc='upper left')  \n",
    "\n",
    "# summarize history for loss  \n",
    "\n",
    "plt.subplot(212)  \n",
    "plt.plot(history.history['loss'])  \n",
    "plt.plot(history.history['val_loss'])  \n",
    "plt.title('model loss')  \n",
    "plt.ylabel('loss')  \n",
    "plt.xlabel('epoch')  \n",
    "plt.legend(['train', 'test'], loc='upper left')  \n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
